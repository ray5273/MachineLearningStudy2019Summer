{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility --> random 값을 매번 같은 것을 반환함\n",
    "#sklearn 추가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 13)\n",
      "(235, 1)\n",
      "(57, 13)\n",
      "(57, 1)\n",
      "\n",
      "(test) hypothesis:  [[0.8650817 ]\n",
      " [0.02060679]\n",
      " [0.02473757]\n",
      " [0.72879183]\n",
      " [0.9183578 ]\n",
      " [0.86647666]\n",
      " [0.3377589 ]\n",
      " [0.71807706]\n",
      " [0.21057904]\n",
      " [0.07346612]\n",
      " [0.76286346]\n",
      " [0.83954906]\n",
      " [0.7596277 ]\n",
      " [0.8851917 ]\n",
      " [0.50462645]\n",
      " [0.7243991 ]\n",
      " [0.95276815]\n",
      " [0.84872854]\n",
      " [0.50332594]\n",
      " [0.9734896 ]\n",
      " [0.41468444]\n",
      " [0.02477533]\n",
      " [0.853901  ]\n",
      " [0.06429639]\n",
      " [0.90944946]\n",
      " [0.13517278]\n",
      " [0.890786  ]\n",
      " [0.7951417 ]\n",
      " [0.6105473 ]\n",
      " [0.8291048 ]\n",
      " [0.8971    ]\n",
      " [0.8940475 ]\n",
      " [0.2086123 ]\n",
      " [0.7084897 ]\n",
      " [0.9244883 ]\n",
      " [0.5568889 ]\n",
      " [0.5544909 ]\n",
      " [0.8416747 ]\n",
      " [0.12545979]\n",
      " [0.03256509]\n",
      " [0.567205  ]\n",
      " [0.5370765 ]\n",
      " [0.52032036]\n",
      " [0.56877387]\n",
      " [0.01448339]\n",
      " [0.978228  ]\n",
      " [0.20061085]\n",
      " [0.68400544]\n",
      " [0.9507536 ]\n",
      " [0.32605702]\n",
      " [0.0260075 ]\n",
      " [0.6086015 ]\n",
      " [0.6401905 ]\n",
      " [0.93022954]\n",
      " [0.04632321]\n",
      " [0.8666786 ]\n",
      " [0.7397519 ]\n",
      " [0.16946724]\n",
      " [0.77048135]\n",
      " [0.8796705 ]\n",
      " [0.25036722]\n",
      " [0.8638315 ]\n",
      " [0.8799261 ]\n",
      " [0.84247696]\n",
      " [0.87659466]\n",
      " [0.5560211 ]\n",
      " [0.06672698]\n",
      " [0.2347579 ]\n",
      " [0.95585525]\n",
      " [0.9585277 ]\n",
      " [0.17990792]\n",
      " [0.06305832]\n",
      " [0.2975822 ]\n",
      " [0.72118807]\n",
      " [0.77029216]\n",
      " [0.7716016 ]\n",
      " [0.92351675]\n",
      " [0.80738765]\n",
      " [0.924688  ]\n",
      " [0.21668413]\n",
      " [0.73120123]\n",
      " [0.17773235]\n",
      " [0.45903876]\n",
      " [0.05968267]\n",
      " [0.38815233]\n",
      " [0.25755006]\n",
      " [0.15787521]\n",
      " [0.95242953]\n",
      " [0.24607858]\n",
      " [0.63106406]\n",
      " [0.8131105 ]\n",
      " [0.9156552 ]\n",
      " [0.13929725]\n",
      " [0.09392744]\n",
      " [0.15610573]\n",
      " [0.02956983]\n",
      " [0.8255586 ]\n",
      " [0.8899882 ]\n",
      " [0.03765133]\n",
      " [0.05745614]\n",
      " [0.86346304]\n",
      " [0.92238396]\n",
      " [0.59582794]\n",
      " [0.3869691 ]\n",
      " [0.42166004]\n",
      " [0.94817233]\n",
      " [0.8558868 ]\n",
      " [0.19846928]\n",
      " [0.10882175]\n",
      " [0.8040135 ]\n",
      " [0.5664214 ]\n",
      " [0.69334745]\n",
      " [0.91528845]\n",
      " [0.24853417]\n",
      " [0.29226285]\n",
      " [0.8957318 ]\n",
      " [0.07179207]\n",
      " [0.9229045 ]\n",
      " [0.8054309 ]\n",
      " [0.949372  ]\n",
      " [0.84961736]\n",
      " [0.7325016 ]\n",
      " [0.8294724 ]\n",
      " [0.05305555]\n",
      " [0.03615779]\n",
      " [0.08427602]\n",
      " [0.25102657]\n",
      " [0.2983121 ]\n",
      " [0.66845465]\n",
      " [0.8010323 ]\n",
      " [0.10012382]\n",
      " [0.937098  ]\n",
      " [0.7329086 ]\n",
      " [0.83365023]\n",
      " [0.29883727]\n",
      " [0.6937914 ]\n",
      " [0.19257402]\n",
      " [0.89524716]\n",
      " [0.09510767]\n",
      " [0.1116513 ]\n",
      " [0.49861574]\n",
      " [0.7751956 ]\n",
      " [0.03539488]\n",
      " [0.27799773]\n",
      " [0.11933967]\n",
      " [0.78681564]\n",
      " [0.65346485]\n",
      " [0.40632498]\n",
      " [0.7601309 ]\n",
      " [0.37929082]\n",
      " [0.8778373 ]\n",
      " [0.13118735]\n",
      " [0.54159474]\n",
      " [0.16576958]\n",
      " [0.9010587 ]\n",
      " [0.0125609 ]\n",
      " [0.37597263]\n",
      " [0.85119   ]\n",
      " [0.06526417]\n",
      " [0.7421093 ]\n",
      " [0.46761855]\n",
      " [0.9408725 ]\n",
      " [0.83934945]\n",
      " [0.8890785 ]\n",
      " [0.6478042 ]\n",
      " [0.7868726 ]\n",
      " [0.8986219 ]\n",
      " [0.02172437]\n",
      " [0.02204034]\n",
      " [0.8334374 ]\n",
      " [0.5193386 ]\n",
      " [0.4388913 ]\n",
      " [0.2066949 ]\n",
      " [0.95848   ]\n",
      " [0.475302  ]\n",
      " [0.48799288]\n",
      " [0.749222  ]\n",
      " [0.9602345 ]\n",
      " [0.9772465 ]\n",
      " [0.96113396]\n",
      " [0.7360166 ]\n",
      " [0.94593215]\n",
      " [0.09338161]\n",
      " [0.19157648]\n",
      " [0.9284492 ]\n",
      " [0.24963501]\n",
      " [0.93532574]\n",
      " [0.0365403 ]\n",
      " [0.04812327]\n",
      " [0.44714054]\n",
      " [0.9131221 ]\n",
      " [0.84748995]\n",
      " [0.8390784 ]\n",
      " [0.946462  ]\n",
      " [0.6089494 ]\n",
      " [0.9481083 ]\n",
      " [0.3589474 ]\n",
      " [0.500296  ]\n",
      " [0.08997613]\n",
      " [0.3373232 ]\n",
      " [0.8075371 ]\n",
      " [0.15315458]\n",
      " [0.05857739]\n",
      " [0.94696784]\n",
      " [0.7003748 ]\n",
      " [0.95496124]\n",
      " [0.7535883 ]\n",
      " [0.7283978 ]\n",
      " [0.89330846]\n",
      " [0.97736925]\n",
      " [0.91018784]\n",
      " [0.06398085]\n",
      " [0.30357316]\n",
      " [0.82550776]\n",
      " [0.6460802 ]\n",
      " [0.88124645]\n",
      " [0.6886309 ]\n",
      " [0.02949473]\n",
      " [0.7900233 ]\n",
      " [0.6743566 ]\n",
      " [0.8522139 ]\n",
      " [0.93462074]\n",
      " [0.6647825 ]\n",
      " [0.8041365 ]\n",
      " [0.06907248]\n",
      " [0.9172142 ]\n",
      " [0.1523864 ]\n",
      " [0.31775457]\n",
      " [0.6534165 ]\n",
      " [0.70565903]\n",
      " [0.56204665]\n",
      " [0.9394511 ]\n",
      " [0.25110775]\n",
      " [0.03601042]\n",
      " [0.5452279 ]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy  0.8468085\n",
      "\n",
      "(training) hypothesis:  [[0.9001119 ]\n",
      " [0.10531864]\n",
      " [0.8679406 ]\n",
      " [0.4164197 ]\n",
      " [0.84803414]\n",
      " [0.01596144]\n",
      " [0.33258423]\n",
      " [0.61084896]\n",
      " [0.02480909]\n",
      " [0.03644183]\n",
      " [0.77010524]\n",
      " [0.87818515]\n",
      " [0.04369408]\n",
      " [0.38390326]\n",
      " [0.76528466]\n",
      " [0.68748856]\n",
      " [0.9238136 ]\n",
      " [0.40310836]\n",
      " [0.5897273 ]\n",
      " [0.73302925]\n",
      " [0.05000994]\n",
      " [0.26353273]\n",
      " [0.06923354]\n",
      " [0.29786322]\n",
      " [0.8449465 ]\n",
      " [0.6025275 ]\n",
      " [0.79233575]\n",
      " [0.42718127]\n",
      " [0.05340281]\n",
      " [0.3373819 ]\n",
      " [0.6456801 ]\n",
      " [0.44522977]\n",
      " [0.01547191]\n",
      " [0.82732517]\n",
      " [0.09588024]\n",
      " [0.19530049]\n",
      " [0.06929752]\n",
      " [0.02090818]\n",
      " [0.2827704 ]\n",
      " [0.4411933 ]\n",
      " [0.9657339 ]\n",
      " [0.6145562 ]\n",
      " [0.10420033]\n",
      " [0.8093521 ]\n",
      " [0.13039696]\n",
      " [0.5802045 ]\n",
      " [0.8322508 ]\n",
      " [0.23317963]\n",
      " [0.96736336]\n",
      " [0.63776654]\n",
      " [0.6718968 ]\n",
      " [0.05524603]\n",
      " [0.8353325 ]\n",
      " [0.9057073 ]\n",
      " [0.4489245 ]\n",
      " [0.9142791 ]\n",
      " [0.6611104 ]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy  0.7719298\n"
     ]
    }
   ],
   "source": [
    "#여기는 강의안 따라 만들어 본 것\n",
    "tf.set_random_seed(777)  # for reproducibility --> random 값을 매번 같은 것을 반환함\n",
    "xy_train = np.loadtxt('Heart_Train_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "xy_test = np.loadtxt('Heart_Test_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "#input data를 normalize 하지 않으면 학습이 제대로 안된다!\n",
    "\n",
    "# 이런식으로 함수를 만들어도 되고 sklearn을 통해서 normalize 함수를 불러와도 되고\n",
    "# def MinMaxScaler(data):\n",
    "#     numerator = data - np.min(data, 0)\n",
    "#     denominator = np.max(data, 0) - np.min(data, 0)\n",
    "#     # noise term prevents the zero division\n",
    "#     return numerator / (denominator + 1e-5)\n",
    "# xy = MinMaxScaler(xy)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "xy_train= scaler.fit_transform(xy_train)\n",
    "xy_test = scaler.fit_transform(xy_test)\n",
    "\n",
    "\n",
    "x_data_train = xy_train[:,0:-1]\n",
    "y_data_train = xy_train[:,[-1]]\n",
    "x_data_test = xy_test[:,0:-1]\n",
    "y_data_test = xy_test[:,[-1]]\n",
    "\n",
    "# x_data_train = xy[:250,0:-1]\n",
    "# x_data_test = xy[250:,0:-1]\n",
    "# y_data_train = xy[:250,[-1]]\n",
    "# y_data_test = xy[250:,[-1]]\n",
    "\n",
    "\n",
    "# print(x_data_train)\n",
    "print(x_data_train.shape)\n",
    "# print(y_data_train)\n",
    "print(y_data_train.shape)\n",
    "\n",
    "# print(x_data_test)\n",
    "print(x_data_test.shape)\n",
    "# print(y_data_test)\n",
    "print(y_data_test.shape)\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,13])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#predicted 값을 설정하기위해서 hypothesis 값을 어떤식으로 조정해야하지?\n",
    "#어떻게 해야 좋은게\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], \n",
    "                               feed_dict={X: x_data_train, Y: y_data_train})\n",
    "#         if step%100 == 0:\n",
    "#             print(step,cost_val)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_train,Y:y_data_train})\n",
    "    print(\"\\n(test) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_test,Y:y_data_test})\n",
    "    print(\"\\n(training) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235,)\n",
      "Test Accuracy (training) 86.38%\n",
      "Test Accuracy (test) 80.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "\n",
    "# error fix link \n",
    "# :https://www.kaggle.com/pratsiuk/valueerror-unknown-label-type-continuous \n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "#np.ravel 이게 뭔지 잘 모르겠네\n",
    "\n",
    "training_scores_y = lab_enc.fit_transform(np.ravel(y_data_train))\n",
    "print(np.ravel(y_data_train).shape)\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr.fit(x_data_train,training_scores_y)\n",
    "print(\"Test Accuracy (training) {:.2f}%\".format(lr.score(x_data_train,y_data_train)*100))\n",
    "print(\"Test Accuracy (test) {:.2f}%\".format(lr.score(x_data_test,y_data_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (training): 0.55\n",
      "Test Accuracy (test): 0.49\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.01).fit(x_data_train,y_data_train)\n",
    "print(\"Test Accuracy (training): {:.2f}\".format(ridge.score(x_data_train, y_data_train)))\n",
    "print(\"Test Accuracy (test): {:.2f}\".format(ridge.score(x_data_test, y_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63.  1.  3. ...  0.  1.  1.]\n",
      " [67.  1.  0. ...  3.  2.  0.]\n",
      " [67.  1.  0. ...  2.  3.  0.]\n",
      " ...\n",
      " [44.  1.  0. ...  0.  1.  0.]\n",
      " [63.  1.  0. ...  2.  3.  0.]\n",
      " [63.  0.  0. ...  0.  2.  0.]]\n",
      "[[ 0.931073    0.7116251   1.9825319  ... -0.7168576  -2.336036\n",
      "   0.87573814]\n",
      " [ 1.3735445   0.7116251  -0.9232581  ...  2.5021527  -0.5708641\n",
      "  -1.1418939 ]\n",
      " [ 1.3735445   0.7116251  -0.9232581  ...  1.4291493   1.1943078\n",
      "  -1.1418939 ]\n",
      " ...\n",
      " [-1.1706665   0.7116251  -0.9232581  ... -0.7168576  -2.336036\n",
      "  -1.1418939 ]\n",
      " [ 0.931073    0.7116251  -0.9232581  ...  1.4291493   1.1943078\n",
      "  -1.1418939 ]\n",
      " [ 0.931073   -1.4052343  -0.9232581  ... -0.7168576  -0.5708641\n",
      "  -1.1418939 ]]\n",
      "[[ 0.931073    0.7116251   1.9825319  ...  2.25724    -0.7168576\n",
      "  -2.336036  ]\n",
      " [ 1.3735445   0.7116251  -0.9232581  ...  0.6449257   2.5021527\n",
      "  -0.5708641 ]\n",
      " [ 1.3735445   0.7116251  -0.9232581  ...  0.6449257   1.4291493\n",
      "   1.1943078 ]\n",
      " ...\n",
      " [-1.1706665   0.7116251  -0.9232581  ...  2.25724    -0.7168576\n",
      "  -2.336036  ]\n",
      " [ 0.931073    0.7116251  -0.9232581  ... -0.96738863  1.4291493\n",
      "   1.1943078 ]\n",
      " [ 0.931073   -1.4052343  -0.9232581  ...  0.6449257  -0.7168576\n",
      "  -0.5708641 ]]\n",
      "0 2.6512516\n",
      "100 0.49119887\n",
      "200 -0.7231099\n",
      "300 -1.5647442\n",
      "400 -2.2500243\n",
      "500 nan\n",
      "600 nan\n",
      "700 nan\n",
      "800 nan\n",
      "900 nan\n",
      "1000 nan\n",
      "1100 nan\n",
      "1200 nan\n",
      "1300 nan\n",
      "1400 nan\n",
      "1500 nan\n",
      "1600 nan\n",
      "1700 nan\n",
      "1800 nan\n",
      "1900 nan\n",
      "2000 nan\n",
      "2100 nan\n",
      "2200 nan\n",
      "2300 nan\n",
      "2400 nan\n",
      "2500 nan\n",
      "2600 nan\n",
      "2700 nan\n",
      "2800 nan\n",
      "2900 nan\n",
      "3000 nan\n",
      "3100 nan\n",
      "3200 nan\n",
      "3300 nan\n",
      "3400 nan\n",
      "3500 nan\n",
      "3600 nan\n",
      "3700 nan\n",
      "3800 nan\n",
      "3900 nan\n",
      "4000 nan\n",
      "4100 nan\n",
      "4200 nan\n",
      "4300 nan\n",
      "4400 nan\n",
      "4500 nan\n",
      "4600 nan\n",
      "4700 nan\n",
      "4800 nan\n",
      "4900 nan\n",
      "5000 nan\n",
      "5100 nan\n",
      "5200 nan\n",
      "5300 nan\n",
      "5400 nan\n",
      "5500 nan\n",
      "5600 nan\n",
      "5700 nan\n",
      "5800 nan\n",
      "5900 nan\n",
      "6000 nan\n",
      "6100 nan\n",
      "6200 nan\n",
      "6300 nan\n",
      "6400 nan\n",
      "6500 nan\n",
      "6600 nan\n",
      "6700 nan\n",
      "6800 nan\n",
      "6900 nan\n",
      "7000 nan\n",
      "7100 nan\n",
      "7200 nan\n",
      "7300 nan\n",
      "7400 nan\n",
      "7500 nan\n",
      "7600 nan\n",
      "7700 nan\n",
      "7800 nan\n",
      "7900 nan\n",
      "8000 nan\n",
      "8100 nan\n",
      "8200 nan\n",
      "8300 nan\n",
      "8400 nan\n",
      "8500 nan\n",
      "8600 nan\n",
      "8700 nan\n",
      "8800 nan\n",
      "8900 nan\n",
      "9000 nan\n",
      "9100 nan\n",
      "9200 nan\n",
      "9300 nan\n",
      "9400 nan\n",
      "9500 nan\n",
      "9600 nan\n",
      "9700 nan\n",
      "9800 nan\n",
      "9900 nan\n",
      "10000 nan\n",
      "\n",
      "(test) hypothesis:  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]] \n",
      "Correct (Y): [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy  0.0\n",
      "\n",
      "(training) hypothesis:  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]] \n",
      "Correct (Y): [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy  0.0\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler\n",
    "xy_train = np.loadtxt('Heart_Train_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "xy_test = np.loadtxt('Heart_Test_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xy_train= scaler.fit_transform(xy_train)\n",
    "xy_test = scaler.fit_transform(xy_test)\n",
    "\n",
    "x_data_train = xy_train[:,0:-1]\n",
    "y_data_train = xy_train[:,[-1]]\n",
    "x_data_test = xy_test[:,0:-1]\n",
    "y_data_test = xy_test[:,[-1]]\n",
    "\n",
    "print(x_data_train)\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,13])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#predicted 값을 설정하기위해서 hypothesis 값을 어떤식으로 조정해야하지?\n",
    "#어떻게 해야 좋은게\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], \n",
    "                               feed_dict={X: x_data_train, Y: y_data_train})\n",
    "        if step%100 == 0:\n",
    "            print(step,cost_val)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_train,Y:y_data_train})\n",
    "    print(\"\\n(test) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_test,Y:y_data_test})\n",
    "    print(\"\\n(training) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
