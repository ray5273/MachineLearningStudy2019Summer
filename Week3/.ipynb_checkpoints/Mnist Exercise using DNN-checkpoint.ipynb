{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-789c87ba5427>:11: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 0001, Cost: 2.326347333\n",
      "Epoch: 0002, Cost: 2.242477263\n",
      "Epoch: 0003, Cost: 2.157014437\n",
      "Epoch: 0004, Cost: 1.998275306\n",
      "Epoch: 0005, Cost: 1.818690872\n",
      "Epoch: 0006, Cost: 1.655386899\n",
      "Epoch: 0007, Cost: 1.500847477\n",
      "Epoch: 0008, Cost: 1.391407885\n",
      "Epoch: 0009, Cost: 1.339013781\n",
      "Epoch: 0010, Cost: 1.308203429\n",
      "Epoch: 0011, Cost: 1.286070384\n",
      "Epoch: 0012, Cost: 1.269176709\n",
      "Epoch: 0013, Cost: 1.255762772\n",
      "Epoch: 0014, Cost: 1.244320510\n",
      "Epoch: 0015, Cost: 1.233710108\n",
      "Epoch: 0016, Cost: 1.224383290\n",
      "Epoch: 0017, Cost: 1.216077602\n",
      "Epoch: 0018, Cost: 1.207224810\n",
      "Epoch: 0019, Cost: 1.197994349\n",
      "Epoch: 0020, Cost: 1.187160932\n",
      "Epoch: 0021, Cost: 1.170984770\n",
      "Epoch: 0022, Cost: 1.149878060\n",
      "Epoch: 0023, Cost: 1.126472518\n",
      "Epoch: 0024, Cost: 1.103347018\n",
      "Epoch: 0025, Cost: 1.076465816\n",
      "Epoch: 0026, Cost: 1.044796616\n",
      "Epoch: 0027, Cost: 1.006564516\n",
      "Epoch: 0028, Cost: 0.978736444\n",
      "Epoch: 0029, Cost: 0.959143173\n",
      "Epoch: 0030, Cost: 0.943288394\n",
      "Epoch: 0031, Cost: 0.931700514\n",
      "Epoch: 0032, Cost: 0.921999113\n",
      "Epoch: 0033, Cost: 0.914455409\n",
      "Epoch: 0034, Cost: 0.907614947\n",
      "Epoch: 0035, Cost: 0.901825008\n",
      "Epoch: 0036, Cost: 0.896822489\n",
      "Epoch: 0037, Cost: 0.891006156\n",
      "Epoch: 0038, Cost: 0.886297701\n",
      "Epoch: 0039, Cost: 0.881880255\n",
      "Epoch: 0040, Cost: 0.877575371\n",
      "Epoch: 0041, Cost: 0.873589894\n",
      "Epoch: 0042, Cost: 0.870298909\n",
      "Epoch: 0043, Cost: 0.866482057\n",
      "Epoch: 0044, Cost: 0.862832139\n",
      "Epoch: 0045, Cost: 0.859830578\n",
      "Epoch: 0046, Cost: 0.856456800\n",
      "Epoch: 0047, Cost: 0.853505291\n",
      "Epoch: 0048, Cost: 0.850663211\n",
      "Epoch: 0049, Cost: 0.847996774\n",
      "Epoch: 0050, Cost: 0.844939059\n",
      "Epoch: 0051, Cost: 0.842078926\n",
      "Epoch: 0052, Cost: 0.839186393\n",
      "Epoch: 0053, Cost: 0.836210041\n",
      "Epoch: 0054, Cost: 0.831826121\n",
      "Epoch: 0055, Cost: 0.826172109\n",
      "Epoch: 0056, Cost: 0.819739481\n",
      "Epoch: 0057, Cost: 0.813246511\n",
      "Epoch: 0058, Cost: 0.807841408\n",
      "Epoch: 0059, Cost: 0.802957717\n",
      "Epoch: 0060, Cost: 0.798296289\n",
      "Epoch: 0061, Cost: 0.793881856\n",
      "Epoch: 0062, Cost: 0.788993673\n",
      "Epoch: 0063, Cost: 0.784563863\n",
      "Epoch: 0064, Cost: 0.780380811\n",
      "Epoch: 0065, Cost: 0.776676228\n",
      "Epoch: 0066, Cost: 0.772338181\n",
      "Epoch: 0067, Cost: 0.768858056\n",
      "Epoch: 0068, Cost: 0.765825612\n",
      "Epoch: 0069, Cost: 0.762467961\n",
      "Epoch: 0070, Cost: 0.759341554\n",
      "Epoch: 0071, Cost: 0.756764949\n",
      "Epoch: 0072, Cost: 0.753841460\n",
      "Epoch: 0073, Cost: 0.751011309\n",
      "Epoch: 0074, Cost: 0.748746638\n",
      "Epoch: 0075, Cost: 0.746589373\n",
      "Epoch: 0076, Cost: 0.744298059\n",
      "Epoch: 0077, Cost: 0.742052522\n",
      "Epoch: 0078, Cost: 0.740154383\n",
      "Epoch: 0079, Cost: 0.737992178\n",
      "Epoch: 0080, Cost: 0.735930375\n",
      "Epoch: 0081, Cost: 0.734153532\n",
      "Epoch: 0082, Cost: 0.731938253\n",
      "Epoch: 0083, Cost: 0.730075557\n",
      "Epoch: 0084, Cost: 0.728228160\n",
      "Epoch: 0085, Cost: 0.726555694\n",
      "Epoch: 0086, Cost: 0.724636900\n",
      "Epoch: 0087, Cost: 0.722736356\n",
      "Epoch: 0088, Cost: 0.721067384\n",
      "Epoch: 0089, Cost: 0.719523150\n",
      "Epoch: 0090, Cost: 0.717777246\n",
      "Epoch: 0091, Cost: 0.715828013\n",
      "Epoch: 0092, Cost: 0.714201238\n",
      "Epoch: 0093, Cost: 0.712437919\n",
      "Epoch: 0094, Cost: 0.710456887\n",
      "Epoch: 0095, Cost: 0.708676573\n",
      "Epoch: 0096, Cost: 0.706691146\n",
      "Epoch: 0097, Cost: 0.704705341\n",
      "Epoch: 0098, Cost: 0.702229874\n",
      "Epoch: 0099, Cost: 0.700190616\n",
      "Epoch: 0100, Cost: 0.697562760\n",
      "Learning finished\n",
      "Accuracy:  0.68\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mnist Exercise using DNN\n",
    "# Mnist Practice\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data .read_data_sets(\"MNIST_data/\",one_hot = True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784,50]))\n",
    "b = tf.Variable(tf.random_normal([50]))\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "layer1 = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([50,50]),name=\"weight\")\n",
    "b1 = tf.Variable(tf.random_normal([50]),name=\"bias\")\n",
    "\n",
    "layer2 = tf.nn.softmax(tf.matmul(layer1, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([50,nb_classes]),name=\"weight\")\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]),name=\"bias\")\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer2,W2)+b2)\n",
    "                           \n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "num_iterations = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([train,cost],feed_dict={X:batch_xs,Y:batch_ys})\n",
    "            avg_cost += cost_val/num_iterations\n",
    "        \n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "        \n",
    "    print(\"Learning finished\")\n",
    "    \n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "    print(\n",
    "        \"Prediction: \",\n",
    "        sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r : r + 1]}),\n",
    "    )\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
