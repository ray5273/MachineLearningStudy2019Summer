{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility --> random 값을 매번 같은 것을 반환함\n",
    "#sklearn 추가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 13)\n",
      "(235, 1)\n",
      "(57, 13)\n",
      "(57, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\sanghyeok\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "(test) hypothesis:  [[0.8650817 ]\n",
      " [0.02060673]\n",
      " [0.02473754]\n",
      " [0.72879195]\n",
      " [0.9183578 ]\n",
      " [0.8664768 ]\n",
      " [0.33775896]\n",
      " [0.718077  ]\n",
      " [0.21057898]\n",
      " [0.07346615]\n",
      " [0.7628635 ]\n",
      " [0.83954906]\n",
      " [0.7596277 ]\n",
      " [0.8851917 ]\n",
      " [0.5046264 ]\n",
      " [0.7243991 ]\n",
      " [0.95276815]\n",
      " [0.84872854]\n",
      " [0.50332594]\n",
      " [0.9734896 ]\n",
      " [0.4146846 ]\n",
      " [0.02477533]\n",
      " [0.853901  ]\n",
      " [0.06429642]\n",
      " [0.9094495 ]\n",
      " [0.13517281]\n",
      " [0.89078593]\n",
      " [0.7951417 ]\n",
      " [0.6105474 ]\n",
      " [0.8291048 ]\n",
      " [0.8971    ]\n",
      " [0.8940474 ]\n",
      " [0.20861235]\n",
      " [0.70848966]\n",
      " [0.92448837]\n",
      " [0.5568888 ]\n",
      " [0.5544909 ]\n",
      " [0.8416747 ]\n",
      " [0.12545985]\n",
      " [0.03256509]\n",
      " [0.567205  ]\n",
      " [0.5370764 ]\n",
      " [0.52032036]\n",
      " [0.5687738 ]\n",
      " [0.01448336]\n",
      " [0.978228  ]\n",
      " [0.20061079]\n",
      " [0.68400556]\n",
      " [0.95075357]\n",
      " [0.3260569 ]\n",
      " [0.0260075 ]\n",
      " [0.6086015 ]\n",
      " [0.6401905 ]\n",
      " [0.93022954]\n",
      " [0.04632321]\n",
      " [0.8666786 ]\n",
      " [0.7397519 ]\n",
      " [0.16946733]\n",
      " [0.7704812 ]\n",
      " [0.8796705 ]\n",
      " [0.25036722]\n",
      " [0.8638315 ]\n",
      " [0.8799261 ]\n",
      " [0.842477  ]\n",
      " [0.87659466]\n",
      " [0.55602103]\n",
      " [0.06672701]\n",
      " [0.23475793]\n",
      " [0.95585525]\n",
      " [0.9585277 ]\n",
      " [0.17990798]\n",
      " [0.06305832]\n",
      " [0.2975822 ]\n",
      " [0.7211881 ]\n",
      " [0.77029216]\n",
      " [0.77160156]\n",
      " [0.92351675]\n",
      " [0.8073876 ]\n",
      " [0.924688  ]\n",
      " [0.21668416]\n",
      " [0.7312012 ]\n",
      " [0.17773238]\n",
      " [0.45903865]\n",
      " [0.05968273]\n",
      " [0.38815227]\n",
      " [0.25755   ]\n",
      " [0.15787515]\n",
      " [0.95242953]\n",
      " [0.24607855]\n",
      " [0.631064  ]\n",
      " [0.8131105 ]\n",
      " [0.91565526]\n",
      " [0.13929725]\n",
      " [0.09392744]\n",
      " [0.15610576]\n",
      " [0.02956983]\n",
      " [0.8255586 ]\n",
      " [0.88998806]\n",
      " [0.03765133]\n",
      " [0.05745614]\n",
      " [0.86346304]\n",
      " [0.92238396]\n",
      " [0.5958279 ]\n",
      " [0.3869691 ]\n",
      " [0.42166004]\n",
      " [0.9481724 ]\n",
      " [0.8558868 ]\n",
      " [0.19846919]\n",
      " [0.10882181]\n",
      " [0.80401355]\n",
      " [0.5664214 ]\n",
      " [0.6933474 ]\n",
      " [0.91528845]\n",
      " [0.24853417]\n",
      " [0.29226285]\n",
      " [0.8957317 ]\n",
      " [0.07179213]\n",
      " [0.9229045 ]\n",
      " [0.8054309 ]\n",
      " [0.94937193]\n",
      " [0.84961736]\n",
      " [0.73250157]\n",
      " [0.8294724 ]\n",
      " [0.05305552]\n",
      " [0.03615773]\n",
      " [0.08427602]\n",
      " [0.25102663]\n",
      " [0.29831204]\n",
      " [0.6684547 ]\n",
      " [0.80103225]\n",
      " [0.10012379]\n",
      " [0.937098  ]\n",
      " [0.7329086 ]\n",
      " [0.83365023]\n",
      " [0.29883727]\n",
      " [0.6937914 ]\n",
      " [0.192574  ]\n",
      " [0.8952472 ]\n",
      " [0.09510767]\n",
      " [0.11165127]\n",
      " [0.49861568]\n",
      " [0.77519554]\n",
      " [0.03539494]\n",
      " [0.27799767]\n",
      " [0.11933973]\n",
      " [0.78681576]\n",
      " [0.6534649 ]\n",
      " [0.40632492]\n",
      " [0.760131  ]\n",
      " [0.37929094]\n",
      " [0.8778373 ]\n",
      " [0.13118735]\n",
      " [0.5415948 ]\n",
      " [0.16576964]\n",
      " [0.9010587 ]\n",
      " [0.01256096]\n",
      " [0.3759727 ]\n",
      " [0.85119   ]\n",
      " [0.06526417]\n",
      " [0.7421093 ]\n",
      " [0.4676185 ]\n",
      " [0.9408725 ]\n",
      " [0.83934945]\n",
      " [0.8890785 ]\n",
      " [0.6478042 ]\n",
      " [0.7868726 ]\n",
      " [0.8986218 ]\n",
      " [0.02172437]\n",
      " [0.02204034]\n",
      " [0.8334374 ]\n",
      " [0.5193386 ]\n",
      " [0.4388914 ]\n",
      " [0.2066949 ]\n",
      " [0.95848   ]\n",
      " [0.47530195]\n",
      " [0.48799288]\n",
      " [0.749222  ]\n",
      " [0.9602346 ]\n",
      " [0.9772465 ]\n",
      " [0.96113396]\n",
      " [0.7360165 ]\n",
      " [0.94593215]\n",
      " [0.09338158]\n",
      " [0.19157648]\n",
      " [0.92844915]\n",
      " [0.24963507]\n",
      " [0.93532574]\n",
      " [0.03654024]\n",
      " [0.0481233 ]\n",
      " [0.44714049]\n",
      " [0.9131221 ]\n",
      " [0.84748995]\n",
      " [0.8390784 ]\n",
      " [0.9464619 ]\n",
      " [0.60894954]\n",
      " [0.9481083 ]\n",
      " [0.3589474 ]\n",
      " [0.50029594]\n",
      " [0.08997616]\n",
      " [0.33732325]\n",
      " [0.8075371 ]\n",
      " [0.15315464]\n",
      " [0.05857739]\n",
      " [0.94696784]\n",
      " [0.7003748 ]\n",
      " [0.9549612 ]\n",
      " [0.75358826]\n",
      " [0.72839785]\n",
      " [0.89330846]\n",
      " [0.97736925]\n",
      " [0.91018796]\n",
      " [0.06398079]\n",
      " [0.3035732 ]\n",
      " [0.8255078 ]\n",
      " [0.64608014]\n",
      " [0.88124645]\n",
      " [0.688631  ]\n",
      " [0.02949464]\n",
      " [0.7900233 ]\n",
      " [0.6743566 ]\n",
      " [0.85221386]\n",
      " [0.93462074]\n",
      " [0.6647825 ]\n",
      " [0.8041365 ]\n",
      " [0.06907246]\n",
      " [0.9172143 ]\n",
      " [0.1523864 ]\n",
      " [0.3177546 ]\n",
      " [0.6534165 ]\n",
      " [0.705659  ]\n",
      " [0.5620466 ]\n",
      " [0.93945104]\n",
      " [0.25110775]\n",
      " [0.03601044]\n",
      " [0.54522777]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy  0.8468085\n",
      "\n",
      "(training) hypothesis:  [[0.9001118 ]\n",
      " [0.10531864]\n",
      " [0.8679406 ]\n",
      " [0.4164197 ]\n",
      " [0.84803414]\n",
      " [0.01596141]\n",
      " [0.3325843 ]\n",
      " [0.61084896]\n",
      " [0.02480909]\n",
      " [0.03644189]\n",
      " [0.77010524]\n",
      " [0.87818515]\n",
      " [0.04369408]\n",
      " [0.38390332]\n",
      " [0.76528466]\n",
      " [0.6874887 ]\n",
      " [0.9238136 ]\n",
      " [0.40310842]\n",
      " [0.5897274 ]\n",
      " [0.73302925]\n",
      " [0.05000991]\n",
      " [0.26353273]\n",
      " [0.06923354]\n",
      " [0.29786322]\n",
      " [0.8449465 ]\n",
      " [0.60252744]\n",
      " [0.79233575]\n",
      " [0.4271813 ]\n",
      " [0.05340275]\n",
      " [0.3373819 ]\n",
      " [0.6456801 ]\n",
      " [0.4452297 ]\n",
      " [0.01547194]\n",
      " [0.82732517]\n",
      " [0.09588033]\n",
      " [0.19530058]\n",
      " [0.06929749]\n",
      " [0.02090821]\n",
      " [0.28277043]\n",
      " [0.4411933 ]\n",
      " [0.9657338 ]\n",
      " [0.6145563 ]\n",
      " [0.10420036]\n",
      " [0.8093521 ]\n",
      " [0.13039696]\n",
      " [0.58020455]\n",
      " [0.8322508 ]\n",
      " [0.23317972]\n",
      " [0.96736336]\n",
      " [0.6377665 ]\n",
      " [0.6718968 ]\n",
      " [0.05524606]\n",
      " [0.8353324 ]\n",
      " [0.9057073 ]\n",
      " [0.44892457]\n",
      " [0.9142791 ]\n",
      " [0.6611105 ]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy  0.7719298\n"
     ]
    }
   ],
   "source": [
    "#여기는 강의안 따라 만들어 본 것\n",
    "tf.set_random_seed(777)  # for reproducibility --> random 값을 매번 같은 것을 반환함\n",
    "xy_train = np.loadtxt('Heart_Train_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "xy_test = np.loadtxt('Heart_Test_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "#input data를 normalize 하지 않으면 학습이 제대로 안된다!\n",
    "\n",
    "# 이런식으로 함수를 만들어도 되고 sklearn을 통해서 normalize 함수를 불러와도 되고\n",
    "# def MinMaxScaler(data):\n",
    "#     numerator = data - np.min(data, 0)\n",
    "#     denominator = np.max(data, 0) - np.min(data, 0)\n",
    "#     # noise term prevents the zero division\n",
    "#     return numerator / (denominator + 1e-5)\n",
    "# xy = MinMaxScaler(xy)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "xy_train= scaler.fit_transform(xy_train)\n",
    "xy_test = scaler.fit_transform(xy_test)\n",
    "\n",
    "\n",
    "x_data_train = xy_train[:,0:-1]\n",
    "y_data_train = xy_train[:,[-1]]\n",
    "x_data_test = xy_test[:,0:-1]\n",
    "y_data_test = xy_test[:,[-1]]\n",
    "\n",
    "# x_data_train = xy[:250,0:-1]\n",
    "# x_data_test = xy[250:,0:-1]\n",
    "# y_data_train = xy[:250,[-1]]\n",
    "# y_data_test = xy[250:,[-1]]\n",
    "\n",
    "\n",
    "# print(x_data_train)\n",
    "print(x_data_train.shape)\n",
    "# print(y_data_train)\n",
    "print(y_data_train.shape)\n",
    "\n",
    "# print(x_data_test)\n",
    "print(x_data_test.shape)\n",
    "# print(y_data_test)\n",
    "print(y_data_test.shape)\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,13])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#predicted 값을 설정하기위해서 hypothesis 값을 어떤식으로 조정해야하지?\n",
    "#어떻게 해야 좋은게\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], \n",
    "                               feed_dict={X: x_data_train, Y: y_data_train})\n",
    "#         if step%100 == 0:\n",
    "#             print(step,cost_val)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_train,Y:y_data_train})\n",
    "    print(\"\\n(test) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_test,Y:y_data_test})\n",
    "    print(\"\\n(training) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235,)\n",
      "Test Accuracy (training) 86.38%\n",
      "Test Accuracy (test) 80.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "\n",
    "# error fix link \n",
    "# :https://www.kaggle.com/pratsiuk/valueerror-unknown-label-type-continuous \n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "#np.ravel 이게 뭔지 잘 모르겠네\n",
    "\n",
    "training_scores_y = lab_enc.fit_transform(np.ravel(y_data_train))\n",
    "print(np.ravel(y_data_train).shape)\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr.fit(x_data_train,training_scores_y)\n",
    "print(\"Test Accuracy (training) {:.2f}%\".format(lr.score(x_data_train,y_data_train)*100))\n",
    "print(\"Test Accuracy (test) {:.2f}%\".format(lr.score(x_data_test,y_data_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (training): 0.55\n",
      "Test Accuracy (test): 0.49\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.01).fit(x_data_train,y_data_train)\n",
    "print(\"Test Accuracy (training): {:.2f}\".format(ridge.score(x_data_train, y_data_train)))\n",
    "print(\"Test Accuracy (test): {:.2f}\".format(ridge.score(x_data_test, y_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.565724\n",
      "100 1.5210612\n",
      "200 0.9320412\n",
      "300 0.64434916\n",
      "400 0.5090576\n",
      "500 0.4416013\n",
      "600 0.404695\n",
      "700 0.3826814\n",
      "800 0.3685787\n",
      "900 0.3590113\n",
      "1000 0.35221246\n",
      "1100 0.34719265\n",
      "1200 0.34336564\n",
      "1300 0.34036767\n",
      "1400 0.33796436\n",
      "1500 0.33599958\n",
      "1600 0.33436626\n",
      "1700 0.33298925\n",
      "1800 0.33181438\n",
      "1900 0.33080176\n",
      "2000 0.32992157\n",
      "2100 0.32915097\n",
      "2200 0.3284722\n",
      "2300 0.32787126\n",
      "2400 0.3273369\n",
      "2500 0.32685992\n",
      "2600 0.32643276\n",
      "2700 0.3260492\n",
      "2800 0.325704\n",
      "2900 0.32539263\n",
      "3000 0.3251113\n",
      "3100 0.32485658\n",
      "3200 0.32462567\n",
      "3300 0.3244161\n",
      "3400 0.3242257\n",
      "3500 0.32405248\n",
      "3600 0.32389474\n",
      "3700 0.32375097\n",
      "3800 0.32361987\n",
      "3900 0.32350013\n",
      "4000 0.32339078\n",
      "4100 0.32329082\n",
      "4200 0.32319933\n",
      "4300 0.3231157\n",
      "4400 0.32303905\n",
      "4500 0.32296887\n",
      "4600 0.32290453\n",
      "4700 0.32284546\n",
      "4800 0.32279125\n",
      "4900 0.3227416\n",
      "5000 0.32269594\n",
      "5100 0.32265398\n",
      "5200 0.32261547\n",
      "5300 0.32258004\n",
      "5400 0.32254744\n",
      "5500 0.32251748\n",
      "5600 0.3224899\n",
      "5700 0.32246447\n",
      "5800 0.32244116\n",
      "5900 0.3224196\n",
      "6000 0.32239974\n",
      "6100 0.3223815\n",
      "6200 0.3223646\n",
      "6300 0.32234907\n",
      "6400 0.32233477\n",
      "6500 0.32232153\n",
      "6600 0.32230935\n",
      "6700 0.3222981\n",
      "6800 0.3222877\n",
      "6900 0.32227808\n",
      "7000 0.3222693\n",
      "7100 0.32226107\n",
      "7200 0.32225356\n",
      "7300 0.32224658\n",
      "7400 0.32224017\n",
      "7500 0.32223418\n",
      "7600 0.32222864\n",
      "7700 0.3222236\n",
      "7800 0.32221884\n",
      "7900 0.3222145\n",
      "8000 0.3222105\n",
      "8100 0.3222068\n",
      "8200 0.32220328\n",
      "8300 0.32220015\n",
      "8400 0.3221972\n",
      "8500 0.3221945\n",
      "8600 0.32219192\n",
      "8700 0.32218963\n",
      "8800 0.32218742\n",
      "8900 0.32218543\n",
      "9000 0.32218352\n",
      "9100 0.32218182\n",
      "9200 0.32218024\n",
      "9300 0.32217878\n",
      "9400 0.3221774\n",
      "9500 0.32217613\n",
      "9600 0.322175\n",
      "9700 0.32217386\n",
      "9800 0.3221729\n",
      "9900 0.32217196\n",
      "10000 0.32217106\n",
      "\n",
      "(test) hypothesis:  [[9.00683284e-01]\n",
      " [1.64309144e-03]\n",
      " [5.44768572e-03]\n",
      " [6.79278076e-01]\n",
      " [9.71648574e-01]\n",
      " [9.35051024e-01]\n",
      " [1.09220475e-01]\n",
      " [9.04102206e-01]\n",
      " [6.93300366e-02]\n",
      " [2.68882513e-02]\n",
      " [7.90975332e-01]\n",
      " [8.88679981e-01]\n",
      " [8.39483380e-01]\n",
      " [9.15399909e-01]\n",
      " [5.65181136e-01]\n",
      " [6.48289919e-01]\n",
      " [9.87960339e-01]\n",
      " [8.96319985e-01]\n",
      " [7.99730659e-01]\n",
      " [9.93026018e-01]\n",
      " [1.80202961e-01]\n",
      " [4.89166379e-03]\n",
      " [8.81668329e-01]\n",
      " [4.34449911e-02]\n",
      " [9.44003105e-01]\n",
      " [8.85224640e-02]\n",
      " [9.29953694e-01]\n",
      " [8.25179219e-01]\n",
      " [7.93874741e-01]\n",
      " [7.92907119e-01]\n",
      " [9.11621392e-01]\n",
      " [9.55843091e-01]\n",
      " [3.58938277e-02]\n",
      " [7.86358774e-01]\n",
      " [9.86400306e-01]\n",
      " [5.64117908e-01]\n",
      " [5.37336886e-01]\n",
      " [9.24984336e-01]\n",
      " [6.49937689e-02]\n",
      " [7.66894221e-03]\n",
      " [4.85268235e-01]\n",
      " [6.33490920e-01]\n",
      " [5.24054229e-01]\n",
      " [8.32917213e-01]\n",
      " [1.99905038e-03]\n",
      " [9.96170640e-01]\n",
      " [7.03087449e-02]\n",
      " [6.15875185e-01]\n",
      " [9.77945209e-01]\n",
      " [1.78611785e-01]\n",
      " [5.05998731e-03]\n",
      " [6.11648381e-01]\n",
      " [7.44494438e-01]\n",
      " [9.53164458e-01]\n",
      " [1.31710470e-02]\n",
      " [8.90657306e-01]\n",
      " [8.27501178e-01]\n",
      " [1.74698979e-01]\n",
      " [8.54607284e-01]\n",
      " [9.28770304e-01]\n",
      " [1.23207211e-01]\n",
      " [9.24386263e-01]\n",
      " [9.43528295e-01]\n",
      " [9.04297411e-01]\n",
      " [9.45082068e-01]\n",
      " [5.49503565e-01]\n",
      " [2.45863199e-03]\n",
      " [6.91251457e-02]\n",
      " [9.95856285e-01]\n",
      " [9.92740452e-01]\n",
      " [1.66420102e-01]\n",
      " [4.44640219e-02]\n",
      " [7.93863833e-02]\n",
      " [7.05120802e-01]\n",
      " [8.68011475e-01]\n",
      " [8.72264266e-01]\n",
      " [9.85283375e-01]\n",
      " [8.76199245e-01]\n",
      " [9.84278798e-01]\n",
      " [7.18002319e-02]\n",
      " [8.21651816e-01]\n",
      " [1.62515134e-01]\n",
      " [4.23124194e-01]\n",
      " [1.58153176e-02]\n",
      " [2.66963065e-01]\n",
      " [2.62180269e-01]\n",
      " [1.26238883e-01]\n",
      " [9.94547367e-01]\n",
      " [1.66370273e-01]\n",
      " [5.96610963e-01]\n",
      " [8.73978496e-01]\n",
      " [9.59689081e-01]\n",
      " [2.04996169e-02]\n",
      " [5.17459810e-02]\n",
      " [1.02107823e-02]\n",
      " [2.72962451e-03]\n",
      " [8.61924887e-01]\n",
      " [9.64934528e-01]\n",
      " [1.66803598e-03]\n",
      " [2.16875672e-02]\n",
      " [9.42336082e-01]\n",
      " [9.80280340e-01]\n",
      " [6.70784295e-01]\n",
      " [7.16548204e-01]\n",
      " [5.63329875e-01]\n",
      " [9.91861701e-01]\n",
      " [9.23520923e-01]\n",
      " [6.64085150e-02]\n",
      " [7.63167739e-02]\n",
      " [8.42722178e-01]\n",
      " [7.63765216e-01]\n",
      " [6.12090528e-01]\n",
      " [9.70691383e-01]\n",
      " [2.44105995e-01]\n",
      " [5.69510460e-01]\n",
      " [9.70259666e-01]\n",
      " [3.69092822e-03]\n",
      " [9.81299162e-01]\n",
      " [8.66828203e-01]\n",
      " [9.91896272e-01]\n",
      " [8.58123422e-01]\n",
      " [8.66399229e-01]\n",
      " [8.65076184e-01]\n",
      " [1.19403899e-02]\n",
      " [1.15414858e-02]\n",
      " [6.64159656e-03]\n",
      " [1.72230661e-01]\n",
      " [1.47058278e-01]\n",
      " [6.72143400e-01]\n",
      " [9.22406197e-01]\n",
      " [6.01325333e-02]\n",
      " [9.87965107e-01]\n",
      " [8.72416735e-01]\n",
      " [8.89889359e-01]\n",
      " [4.03075516e-01]\n",
      " [8.95889163e-01]\n",
      " [2.04440385e-01]\n",
      " [9.79442716e-01]\n",
      " [1.95101798e-02]\n",
      " [6.91495836e-02]\n",
      " [5.52748978e-01]\n",
      " [7.58102775e-01]\n",
      " [5.13067842e-03]\n",
      " [1.40218645e-01]\n",
      " [6.22579753e-02]\n",
      " [7.28786945e-01]\n",
      " [6.27338409e-01]\n",
      " [3.21582377e-01]\n",
      " [7.30704606e-01]\n",
      " [7.29432404e-02]\n",
      " [9.40887928e-01]\n",
      " [4.98329699e-02]\n",
      " [2.21632093e-01]\n",
      " [3.14131379e-02]\n",
      " [9.65074778e-01]\n",
      " [5.13792038e-04]\n",
      " [1.10121816e-01]\n",
      " [9.42890882e-01]\n",
      " [4.47001755e-02]\n",
      " [7.18327284e-01]\n",
      " [7.00393915e-01]\n",
      " [9.83864665e-01]\n",
      " [8.51257503e-01]\n",
      " [9.71691012e-01]\n",
      " [6.76120102e-01]\n",
      " [8.25711727e-01]\n",
      " [9.48342800e-01]\n",
      " [3.77088785e-03]\n",
      " [3.13603878e-03]\n",
      " [8.91687036e-01]\n",
      " [6.34271383e-01]\n",
      " [5.42936385e-01]\n",
      " [9.35939550e-02]\n",
      " [9.95427132e-01]\n",
      " [7.17114091e-01]\n",
      " [2.62858123e-01]\n",
      " [7.81539679e-01]\n",
      " [9.95711207e-01]\n",
      " [9.98716891e-01]\n",
      " [9.93671119e-01]\n",
      " [8.25710952e-01]\n",
      " [9.79231596e-01]\n",
      " [1.00124806e-01]\n",
      " [2.64900208e-01]\n",
      " [9.85710502e-01]\n",
      " [6.48175776e-02]\n",
      " [9.71338630e-01]\n",
      " [6.34035468e-03]\n",
      " [1.65350437e-02]\n",
      " [3.44860315e-01]\n",
      " [9.71416414e-01]\n",
      " [9.13639665e-01]\n",
      " [9.30491090e-01]\n",
      " [9.85505819e-01]\n",
      " [4.41461504e-01]\n",
      " [9.90094006e-01]\n",
      " [1.98351294e-01]\n",
      " [5.38694918e-01]\n",
      " [6.40466809e-02]\n",
      " [1.61379665e-01]\n",
      " [8.86906922e-01]\n",
      " [2.07132399e-02]\n",
      " [2.63731182e-02]\n",
      " [9.88704562e-01]\n",
      " [7.20344901e-01]\n",
      " [9.94249582e-01]\n",
      " [8.59470367e-01]\n",
      " [6.91755831e-01]\n",
      " [9.68441427e-01]\n",
      " [9.95164633e-01]\n",
      " [9.72977996e-01]\n",
      " [1.65259540e-02]\n",
      " [2.16626406e-01]\n",
      " [8.39484453e-01]\n",
      " [5.47376871e-01]\n",
      " [9.50452805e-01]\n",
      " [4.41894978e-01]\n",
      " [3.67677212e-03]\n",
      " [9.01462436e-01]\n",
      " [5.97212911e-01]\n",
      " [9.22331929e-01]\n",
      " [9.83180642e-01]\n",
      " [5.82233071e-01]\n",
      " [8.87347579e-01]\n",
      " [2.30356455e-02]\n",
      " [9.70326185e-01]\n",
      " [1.28642887e-01]\n",
      " [1.57777369e-01]\n",
      " [7.12909460e-01]\n",
      " [8.30252767e-01]\n",
      " [4.82258469e-01]\n",
      " [9.72597957e-01]\n",
      " [2.70353943e-01]\n",
      " [4.66291374e-03]\n",
      " [8.39597702e-01]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy  0.87234044\n",
      "\n",
      "(training) hypothesis:  [[0.9797973 ]\n",
      " [0.04500288]\n",
      " [0.9716182 ]\n",
      " [0.4530629 ]\n",
      " [0.95839274]\n",
      " [0.00351131]\n",
      " [0.62453175]\n",
      " [0.7635274 ]\n",
      " [0.00805131]\n",
      " [0.02046457]\n",
      " [0.80690813]\n",
      " [0.9656515 ]\n",
      " [0.039718  ]\n",
      " [0.4636383 ]\n",
      " [0.8809079 ]\n",
      " [0.8032408 ]\n",
      " [0.9897057 ]\n",
      " [0.36342883]\n",
      " [0.4539389 ]\n",
      " [0.908743  ]\n",
      " [0.03156331]\n",
      " [0.5265202 ]\n",
      " [0.05019012]\n",
      " [0.5572711 ]\n",
      " [0.95333666]\n",
      " [0.8083579 ]\n",
      " [0.9131321 ]\n",
      " [0.6442962 ]\n",
      " [0.03456137]\n",
      " [0.37722474]\n",
      " [0.8478515 ]\n",
      " [0.85693127]\n",
      " [0.00536972]\n",
      " [0.95673716]\n",
      " [0.01564232]\n",
      " [0.05192414]\n",
      " [0.05885983]\n",
      " [0.00333446]\n",
      " [0.5981005 ]\n",
      " [0.85333616]\n",
      " [0.9977727 ]\n",
      " [0.6526317 ]\n",
      " [0.07721901]\n",
      " [0.95264363]\n",
      " [0.0478895 ]\n",
      " [0.6819023 ]\n",
      " [0.9224602 ]\n",
      " [0.08659995]\n",
      " [0.997519  ]\n",
      " [0.8000604 ]\n",
      " [0.9316648 ]\n",
      " [0.05031306]\n",
      " [0.9925059 ]\n",
      " [0.9701266 ]\n",
      " [0.745311  ]\n",
      " [0.9880898 ]\n",
      " [0.5996712 ]] \n",
      "Correct (Y): [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy  0.8245614\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler\n",
    "xy_train = np.loadtxt('Heart_Train_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "xy_test = np.loadtxt('Heart_Test_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_data_train = xy_train[:,0:-1]\n",
    "y_data_train = xy_train[:,[-1]]\n",
    "\n",
    "x_data_test = xy_test[:,0:-1]\n",
    "y_data_test = xy_test[:,[-1]]\n",
    "# xy_train= scaler.fit_transform(xy_train)\n",
    "# xy_test = scaler.fit_transform(xy_test)\n",
    "\n",
    "x_data_train = scaler.fit_transform(x_data_train)\n",
    "x_data_test = scaler.fit_transform(x_data_test)\n",
    "\n",
    "# print(y_data_train)\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,13])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#predicted 값을 설정하기위해서 hypothesis 값을 어떤식으로 조정해야하지?\n",
    "#어떻게 해야 좋은게\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], \n",
    "                               feed_dict={X: x_data_train, Y: y_data_train})\n",
    "        if step%100 == 0:\n",
    "            print(step,cost_val)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_train,Y:y_data_train})\n",
    "    print(\"\\n(test) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis,predicted, accuracy],\n",
    "                               feed_dict = {X:x_data_test,Y:y_data_test})\n",
    "    print(\"\\n(training) hypothesis: \",h,\"\\nCorrect (Y):\",c,\"\\nAccuracy \",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[1.] [0, 1]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "[0.] [1, 0]\n",
      "(235, 13)\n",
      "Tensor(\"Softmax_18:0\", shape=(?, 2), dtype=float32)\n",
      "0 0.9725322\n",
      "200 0.6540695\n",
      "400 0.6078578\n",
      "600 0.57304096\n",
      "800 0.54424626\n",
      "1000 0.5201676\n",
      "1200 0.49985313\n",
      "1400 0.4825743\n",
      "1600 0.46776655\n",
      "1800 0.45498845\n",
      "2000 0.4438917\n",
      "2200 0.4341989\n",
      "2400 0.4256873\n",
      "2600 0.41817665\n",
      "2800 0.41151947\n",
      "3000 0.40559426\n",
      "3200 0.40030015\n",
      "3400 0.39555278\n",
      "3600 0.391281\n",
      "3800 0.38742462\n",
      "4000 0.3839323\n",
      "4200 0.38076007\n",
      "4400 0.37787017\n",
      "4600 0.3752299\n",
      "4800 0.37281102\n",
      "5000 0.37058872\n",
      "5200 0.36854178\n",
      "5400 0.36665127\n",
      "5600 0.36490086\n",
      "5800 0.36327595\n",
      "6000 0.361764\n",
      "6200 0.3603538\n",
      "6400 0.3590354\n",
      "6600 0.35780004\n",
      "6800 0.35664\n",
      "7000 0.35554844\n",
      "7200 0.3545192\n",
      "7400 0.35354686\n",
      "7600 0.3526266\n",
      "7800 0.35175395\n",
      "8000 0.35092518\n",
      "8200 0.35013682\n",
      "8400 0.34938562\n",
      "8600 0.3486689\n",
      "8800 0.34798408\n",
      "9000 0.34732896\n",
      "9200 0.34670138\n",
      "9400 0.34609947\n",
      "9600 0.3455216\n",
      "9800 0.34496623\n",
      "10000 0.3444319\n",
      "Accuracy:  0.7894737\n"
     ]
    }
   ],
   "source": [
    "#여기는 강의안 따라 만들어 본 것 + Softmax\n",
    "tf.set_random_seed(777)  # for reproducibility --> random 값을 매번 같은 것을 반환함\n",
    "xy_train = np.loadtxt('Heart_Train_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "xy_test = np.loadtxt('Heart_Test_Changed.csv',skiprows=1,delimiter=',',dtype=np.float32)\n",
    "#input data를 normalize 하지 않으면 학습이 제대로 안된다!\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "xy_train= scaler.fit_transform(xy_train)\n",
    "xy_test = scaler.fit_transform(xy_test)\n",
    "\n",
    "\n",
    "x_data_train = xy_train[:,0:-1]\n",
    "y_data_train = xy_train[:,[-1]]\n",
    "x_data_test = xy_test[:,0:-1]\n",
    "y_data_test = xy_test[:,[-1]]\n",
    "\n",
    "\n",
    "\n",
    "#0,1 data를 one hot 방식으로 두가지 클래스로 나눠서 y값에 다시 넣어줌 (softmax 를 위해서)\n",
    "y_data_modified_for_softmax = []\n",
    "for i in range(len(y_data_train)):\n",
    "    if y_data_train[i]==0: \n",
    "        y_data_modified_for_softmax.append([1,0])\n",
    "    else:\n",
    "        y_data_modified_for_softmax.append([0,1])\n",
    "        \n",
    "y_data_modified_for_softmax_test = []\n",
    "for i in range(len(y_data_test)):\n",
    "    if y_data_test[i]==0: \n",
    "        y_data_modified_for_softmax_test.append([1,0])\n",
    "    else:\n",
    "        y_data_modified_for_softmax_test.append([0,1])        \n",
    "\n",
    "for i in range(len(y_data_train)):\n",
    "        print(y_data_train[i],y_data_modified_for_softmax[i])\n",
    "print(x_data_train.shape)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,13])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,2])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13,2]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([2]),name='bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "\n",
    "print(hypothesis)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _,cost_val = sess.run([train,cost], \n",
    "                               feed_dict={X: x_data_train, Y: y_data_modified_for_softmax})\n",
    "        if step%200 == 0:\n",
    "             print(step,cost_val)\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: x_data_test, Y: y_data_modified_for_softmax_test}\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
